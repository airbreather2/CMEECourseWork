abundance_list[[octave_interval_count]] <- octaves(species_abundance(community))
}
# Perform one step of the neutral model with speciation
community <- neutral_generation_speciation(community, speciation_rate)
}
# Calculate total execution time
total_time <- (proc.time() - start_time)[3] / 60  # Convert seconds to minutes
# Save the output results
save(time_series, abundance_list, community, total_time,
speciation_rate, size, wall_time, interval_rich, interval_oct, burn_in_generations,
file = output_file_name)
}
neutral_cluster_run(speciation_rate=0.005402, size=100,
wall_time=1, interval_rich=1, interval_oct=10,
burn_in_generations=200,
output_file_name= "results/my_test_file_1.rda")
source("~/Documents/HPC/code/Sebd_HPC_2024_main.R")
ls(abundance_list)
load("results/my_test_file_1.rda")
print(community)
print(community[1:5])
ls()
print(community)  # See final species composition
table(community)  # Frequency table of species
print(total_time)  # Should be close to `wall_time`
source("~/Documents/HPC/code/Get_my_seed.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
setwd("~/Documents/HPC/code")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/code/Sed24_HPC_Main_clusterrun.R")
source("~/Documents/HPC/sed24_HPC_2024_main.R")
setwd("~/Documents/HPC")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
setwd("~/Documents/HPC")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
setwd("~/Documents/HPC")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
setwd("~/Documents/HPC")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
load("~/Documents/HPC/neutral_run4.rda")
load("~/Documents/HPC/HPC_sed24_Handin/sean_data/neutral_run1.rda")
load("~/Documents/HPC/neutral_run4.rda")
setwd("~/Documents/HPC")
source("~/Documents/HPC/sed24_HPC_2024_neutral_cluster.R")
setwd("~/Documents/HPC/HPC_sed24_Handin")
source("~/Documents/HPC/HPC_sed24_Handin/sed24_HPC_2024_main.R")
question_5()
question_5 <- function() {
rdafiles <- list.files(path = "Demographic_output_data/.", pattern = ".*[0-9]+\\.rda$", full.names = TRUE)
print(rdafiles)  # Debugging: Check if any files are found
if (length(rdafiles) == 0) {
stop("No .rda files found in directory")
}
# 1. Define counters for each conditionâ€™s total extinctions and total runs
LA_extinction_counter <- 0
SA_extinction_counter <- 0
LS_extinction_counter <- 0
SS_extinction_counter <- 0
LA_total_sims <- 0
SA_total_sims <- 0
LS_total_sims <- 0
SS_total_sims <- 0
# 2. Loop over every .rda file
for (f in seq_along(rdafiles)) {
file_path <- rdafiles[f]
# Extract HPC job index from filename, e.g. "output_17.rda" => 17
file_name <- basename(file_path)  # "output_17.rda"
iter_str  <- sub("output_(\\d+)\\.rda", "\\1", file_name)
job_idx   <- as.numeric(iter_str)
# 3. Determine the condition name the same way the cluster script does
mod_val <- job_idx %% 4
if (mod_val == 1) {
cond_name <- "large spread"
} else if (mod_val == 2) {
cond_name <- "small adult"
} else if (mod_val == 3) {
cond_name <- "small spread"
} else {
# mod_val == 0
cond_name <- "large adult"
}
# Load the HPC object "simulation_results"
load(file_path)
# Count total sims in this file (should be 150)
num_simulations <- length(simulation_results)
# Determine how many ended in extinction (final pop == 0)
extinct_vec <- sapply(simulation_results, function(x) tail(x, 1) == 0)
n_extinct   <- sum(extinct_vec)
# 4. Update counters for whichever condition
if (cond_name == "large adult") {
LA_extinction_counter <- LA_extinction_counter + n_extinct
LA_total_sims         <- LA_total_sims + num_simulations
} else if (cond_name == "small adult") {
SA_extinction_counter <- SA_extinction_counter + n_extinct
SA_total_sims         <- SA_total_sims + num_simulations
} else if (cond_name == "large spread") {
LS_extinction_counter <- LS_extinction_counter + n_extinct
LS_total_sims         <- LS_total_sims + num_simulations
} else if (cond_name == "small spread") {
SS_extinction_counter <- SS_extinction_counter + n_extinct
SS_total_sims         <- SS_total_sims + num_simulations
}
}
# 5. Compute proportions for each condition
large_adult_extinction  <- LA_extinction_counter / LA_total_sims
small_adult_extinction  <- SA_extinction_counter / SA_total_sims
large_spread_extinction <- LS_extinction_counter / LS_total_sims
small_spread_extinction <- SS_extinction_counter / SS_total_sims
# Print a summary
cat("---- Extinction Counts ----\n")
cat("Large Adult Extinctions:", LA_extinction_counter, "/", LA_total_sims, "\n")
cat("Small Adult Extinctions:", SA_extinction_counter, "/", SA_total_sims, "\n")
cat("Large Spread Extinctions:", LS_extinction_counter, "/", LS_total_sims, "\n")
cat("Small Spread Extinctions:", SS_extinction_counter, "/", SS_total_sims, "\n\n")
# 6. Create a barplot of all 4 proportions
extinction_rates <- c(
large_adult_extinction,
small_adult_extinction,
large_spread_extinction,
small_spread_extinction
)
labels <- c("Large Adult", "Small Adult", "Large Spread", "Small Spread")
cat("---- Extinction Proportions ----\n")
print(extinction_rates)
# Save a barplot
png("question_5.png", width = 600, height = 400)
barplot(
extinction_rates,
names.arg = labels,
xlab = "Initial Condition",
ylab = "Proportion of simulations that ended in extinction",
main = "Extinction Probabilities by Initial Condition",
col = "skyblue"
)
dev.off()
print("Simulation analysis complete")
return("Stochastic simulations with small initial population sizes are are more prone to extinction due to a higher vulnerability to variability within the stochastic model. Inital states containing only mature adults reach extinction in less cases due to an initial uptick in new juveniles in early stages reducing vulnerability to variation in population")
}
question_5()
# Question 6
question_6 <- function() {
# -----------------------------
# 1) FIND .RDA FILES
# -----------------------------
rda_files <- list.files(
path = "Demographic_output_data/.",         # directory to look in
pattern = ".*[0-9]+\\.rda$",     # only .rda files
full.names = TRUE        # include full path
)
if (length(rda_files) == 0) {
stop("No .rda files found in 'output' directory.")
}
# -----------------------------
# 2) INITIAL SETUP & MATRICES
# -----------------------------
num_stages   <- 4
simul_length <- 120
# HPC code sets large_spread=100, small_spread=10
large_initial_spread <- 100
small_initial_spread <- 10
# Spread these totals among 4 stages
large_spread_state <- state_initialise_spread(num_stages, large_initial_spread)
small_spread_state <- state_initialise_spread(num_stages, small_initial_spread)
growth_matrix <- matrix(
c(0.1, 0.0, 0.0, 0.0,
0.5, 0.4, 0.0, 0.0,
0.0, 0.4, 0.7, 0.0,
0.0, 0.0, 0.25, 0.4),
nrow = num_stages, byrow = TRUE
)
reproduction_matrix <- matrix(
c(0.0, 0.0, 0.0, 2.6,
0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0),
nrow = num_stages, byrow = TRUE
)
projection_matrix <- reproduction_matrix + growth_matrix
# -----------------------------
# 3) DETERMINISTIC SIMULATIONS
# -----------------------------
# deterministic_simulation() returns a length-121 numeric vector (time=0..120)
det_large_spread <- deterministic_simulation(large_spread_state, projection_matrix, simul_length)
det_small_spread <- deterministic_simulation(small_spread_state, projection_matrix, simul_length)
# -----------------------------
# 4) ACCUMULATORS FOR STOCHASTIC
# -----------------------------
total_sims_sum_large <- rep(0, simul_length + 1)  # length 121
total_sims_sum_small <- rep(0, simul_length + 1)
count_large <- 0
count_small <- 0
# -----------------------------
# 5) LOOP OVER .rda FILES
# -----------------------------
for (f in seq_along(rda_files)) {
file_path <- rda_files[f]
# Load simulation_results (list of numeric vectors, each length ~121)
load(file_path)
# Extract HPC job index, e.g. "output_17.rda" => 17
file_name <- basename(file_path)
iter_str  <- sub("output_(\\d+)\\.rda", "\\1", file_name)
job_idx   <- as.numeric(iter_str)
# HPC logic: 0=large_adult, 1=large_spread, 2=small_adult, 3=small_spread
mod_val <- job_idx %% 4
if (mod_val == 1) {
cond_name <- "large spread"
} else if (mod_val == 3) {
cond_name <- "small spread"
} else {
# skip large_adult(0) & small_adult(2)
next
}
# simulation_results is a list of length 150 (by default),
# each element is a numeric vector of length 121
for (i in seq_along(simulation_results)) {
sim_vec <- simulation_results[[i]]
# keep all 121 points:
if (cond_name == "large spread") {
total_sims_sum_large <- total_sims_sum_large + sim_vec
count_large <- count_large + 1
} else {
# small spread
total_sims_sum_small <- total_sims_sum_small + sim_vec
count_small <- count_small + 1
}
}
}
# -----------------------------
# 6) AVERAGE STOCHASTIC TRENDS
# -----------------------------
mean_large_spread <- total_sims_sum_large / max(count_large, 1)
mean_small_spread <- total_sims_sum_small / max(count_small, 1)
# -----------------------------
# 7) COMPUTE DEVIATION
# -----------------------------
# Ratio of mean stochastic to deterministic, each length 121
deviation_large <- mean_large_spread / det_large_spread
deviation_small <- mean_small_spread / det_small_spread
# -----------------------------
# 8) MAKE THE PLOT
# -----------------------------
png("question_6.png", width = 600, height = 400)
# Time axis = 0..120
time_axis <- 0:simul_length
# Set up a 1-row, 2-column layout to produce two separate panels
par(mfrow = c(1, 2))
# Panel 1: Large spread
plot(
time_axis, deviation_large, type = "l", col = "blue",
ylim = c(0.95, max(deviation_large, na.rm = TRUE) * 1.03),
xlab = "Time step", ylab = "Deviation (Stochastic / Deterministic)",
main = "Deviation: Large Spread"
)
abline(h = 1, col = "darkgray", lty = 2)  # reference line at 1
# Panel 2: Small spread
plot(
time_axis, deviation_small, type = "l", col = "red",
ylim = c(0.95, max(deviation_small, na.rm = TRUE) * 1.03),
xlab = "Time step", ylab = "Deviation (Stochastic / Deterministic)",
main = "Deviation: Small Spread"
)
abline(h = 1, col = "darkgray", lty = 2)
dev.off()
# -----------------------------
# 9) RETURN WRITTEN ANSWER
# -----------------------------
return(
paste(
"For the large-spread initial condition, the deterministic model",
"more closely approximates the average stochastic trend. When the",
"initial population is large, random variation has a smaller relative",
"impact, so the mean stochastic trajectory remains closer to deterministic in comparison to the small-spread initial condition"
)
)
}
question_6()
# Question 6
question_6 <- function() {
# -----------------------------
# 1) FIND .RDA FILES
# -----------------------------
rda_files <- list.files(
path = "Demographic_output_data/.",         # directory to look in
pattern = ".*[0-9]+\\.rda$",     # only .rda files
full.names = TRUE        # include full path
)
if (length(rda_files) == 0) {
stop("No .rda files found in 'output' directory.")
}
# -----------------------------
# 2) INITIAL SETUP & MATRICES
# -----------------------------
num_stages   <- 4
simul_length <- 120
# HPC code sets large_spread=100, small_spread=10
large_initial_spread <- 100
small_initial_spread <- 10
# Spread these totals among 4 stages
large_spread_state <- state_initialise_spread(num_stages, large_initial_spread)
small_spread_state <- state_initialise_spread(num_stages, small_initial_spread)
growth_matrix <- matrix(
c(0.1, 0.0, 0.0, 0.0,
0.5, 0.4, 0.0, 0.0,
0.0, 0.4, 0.7, 0.0,
0.0, 0.0, 0.25, 0.4),
nrow = num_stages, byrow = TRUE
)
reproduction_matrix <- matrix(
c(0.0, 0.0, 0.0, 2.6,
0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0,
0.0, 0.0, 0.0, 0.0),
nrow = num_stages, byrow = TRUE
)
projection_matrix <- reproduction_matrix + growth_matrix
# -----------------------------
# 3) DETERMINISTIC SIMULATIONS
# -----------------------------
# deterministic_simulation() returns a length-121 numeric vector (time=0..120)
det_large_spread <- deterministic_simulation(large_spread_state, projection_matrix, simul_length)
det_small_spread <- deterministic_simulation(small_spread_state, projection_matrix, simul_length)
# -----------------------------
# 4) ACCUMULATORS FOR STOCHASTIC
# -----------------------------
total_sims_sum_large <- rep(0, simul_length + 1)  # length 121
total_sims_sum_small <- rep(0, simul_length + 1)
count_large <- 0
count_small <- 0
# -----------------------------
# 5) LOOP OVER .rda FILES
# -----------------------------
for (f in seq_along(rda_files)) {
file_path <- rda_files[f]
# Load simulation_results (list of numeric vectors, each length ~121)
load(file_path)
# Extract HPC job index, e.g. "output_17.rda" => 17
file_name <- basename(file_path)
iter_str  <- sub("output_(\\d+)\\.rda", "\\1", file_name)
job_idx   <- as.numeric(iter_str)
# HPC logic: 0=large_adult, 1=large_spread, 2=small_adult, 3=small_spread
mod_val <- job_idx %% 4
if (mod_val == 1) {
cond_name <- "large spread"
} else if (mod_val == 3) {
cond_name <- "small spread"
} else {
# skip large_adult(0) & small_adult(2)
next
}
# simulation_results is a list of length 150 (by default),
# each element is a numeric vector of length 121
for (i in seq_along(simulation_results)) {
sim_vec <- simulation_results[[i]]
# keep all 121 points:
if (cond_name == "large spread") {
total_sims_sum_large <- total_sims_sum_large + sim_vec
count_large <- count_large + 1
} else {
# small spread
total_sims_sum_small <- total_sims_sum_small + sim_vec
count_small <- count_small + 1
}
}
}
# -----------------------------
# 6) AVERAGE STOCHASTIC TRENDS
# -----------------------------
mean_large_spread <- total_sims_sum_large / max(count_large, 1)
mean_small_spread <- total_sims_sum_small / max(count_small, 1)
# -----------------------------
# 7) COMPUTE DEVIATION
# -----------------------------
# Ratio of mean stochastic to deterministic, each length 121
deviation_large <- mean_large_spread / det_large_spread
deviation_small <- mean_small_spread / det_small_spread
# -----------------------------
# 8) MAKE THE PLOT
# -----------------------------
png("question_6.png", width = 600, height = 400)
# Time axis = 0..120
time_axis <- 0:simul_length
# Set up a 1-row, 2-column layout to produce two separate panels
par(mfrow = c(1, 2))
# Panel 1: Large spread
plot(
time_axis, deviation_large, type = "l", col = "blue",
ylim = c(0.95, max(deviation_large, na.rm = TRUE) * 1.03),
xlab = "Time step", ylab = "Deviation (Stochastic / Deterministic)",
main = "Deviation: Large Spread"
)
abline(h = 1, col = "darkgray", lty = 2)  # reference line at 1
# Panel 2: Small spread
plot(
time_axis, deviation_small, type = "l", col = "red",
ylim = c(0.95, max(deviation_small, na.rm = TRUE) * 1.03),
xlab = "Time step", ylab = "Deviation (Stochastic / Deterministic)",
main = "Deviation: Small Spread"
)
abline(h = 1, col = "darkgray", lty = 2)
dev.off()
# -----------------------------
# 9) RETURN WRITTEN ANSWER
# -----------------------------
return(
paste(
"For the large-spread initial condition, the deterministic model",
"more closely approximates the average stochastic trend. When the",
"initial population is large, random variation has a smaller relative",
"impact, so the mean stochastic trajectory remains closer to deterministic in comparison to the small-spread initial condition"
)
)
}
question_6()
# Challenge question A
Challenge_A <- function() {
# -----------------------------
# 1) FIND .RDA FILES
# -----------------------------
rda_files <- list.files(
path = "Demographic_output_data/.",
pattern = ".*[0-9]+\\.rda$",
full.names = TRUE
)
if (length(rda_files) == 0) {
stop("No .rda files found in the directory.")
}
# -----------------------------
# 2) PARALLEL PROCESSING OF .RDA FILES (Base R Implementation)
# -----------------------------
# Detect available cores and use them (avoid maxing out system)
num_cores <- parallel::detectCores() - 1  # Use all but one core
cl <- parallel::makeCluster(num_cores)  # Initialize the cluster
# Export necessary functions and variables to the workers
parallel::clusterExport(cl, c("simulation_results", "list.files"))
process_rda_file <- function(file_path) {
# Extract HPC job index from filename, e.g. "output_17.rda" => 17
file_name <- basename(file_path)
iter_str  <- sub("output_(\\d+)\\.rda", "\\1", file_name)
job_idx   <- as.numeric(iter_str)
# Determine initial condition
mod_val <- job_idx %% 4
cond_name <- ifelse(mod_val == 1, "large spread",
ifelse(mod_val == 2, "small adult",
ifelse(mod_val == 3, "small spread", "large adult")))
# Load the HPC object "simulation_results"
load(file_path)
if (!exists("simulation_results")) {
return(NULL)  # Skip if no data
}
# Process simulations using base R list
sim_data <- lapply(seq_along(simulation_results), function(sim_idx) {
time_series <- simulation_results[[sim_idx]]
if (is.null(time_series) || length(time_series) == 0) return(NULL)
# Return a data.frame for the simulation
data.frame(
simulation_number = sim_idx,
initial_condition = cond_name,
time_step = seq_along(time_series) - 1,
population_size = time_series
)
})
# Combine all simulations into one data.frame
sim_data_combined <- do.call(rbind, sim_data)
return(sim_data_combined)
}
# Process `.rda` files in parallel using parLapply
population_data_list <- parallel::parLapply(cl, rda_files, process_rda_file)
# Stop the cluster
parallel::stopCluster(cl)
# Combine all processed files into a single data frame
population_size_df <- do.call(rbind, population_data_list)
# -----------------------------
# 3) SAVE AND PLOT RESULTS
# -----------------------------
# Save the long-form data table
save(population_size_df, file = "Challenge_A_population_data.rda")
# Check if data exists before plotting
if (nrow(population_size_df) == 0) {
stop("Error: No data available for plotting.")
}
# Plot population trajectories over time using ggplot2
library(ggplot2)
plot <- ggplot(population_size_df, aes(x = time_step, y = population_size,
group = simulation_number, colour = initial_condition)) +
geom_line(alpha = 0.1) +
theme_classic() +
labs(x = "Time Step", y = "Population Size",
title = "Population Size Trajectories Over Time") +
theme(plot.title = element_text(hjust = 0.5))
# Save the plot
ggsave(filename = "Challenge_A.png", plot = plot, device = "png", width = 12, height = 8, units = "in")
return("Challenge A completed: Population trajectories saved and plotted.")
}
Challenge_A()
setwd("~/Documents/CMEECourseWork/HPC_sed24_Handin")
