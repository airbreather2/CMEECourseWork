{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical session 2. Nucleotide substitution & MCMC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numpy is the standard numeric libray\n",
    "import scipy.stats as ss # scipy is the scientific library, the stats module contains different functions\n",
    "import matplotlib.pyplot as plt # matplotlib is the standard plotting library\n",
    "import seaborn as sns # library for statistical plotting\n",
    "import pymc as pm # library for Bayesian MCMC inference\n",
    "import arviz as az # library to analyze and plot Bayesian results\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical we want to infer different substitution rates by comparing two different DNA sequences. The data that we will be using is the 12S rRNA alignment of human and orangutan. The output of the alignment is the count of different nucleotides which consists of 948 base pairs (Genbank accesion numbers for the human and orangutan sequences are D38112 and NC_001646, respectively (Horai et al. (1995)).):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_human</th>\n",
       "      <th>C_human</th>\n",
       "      <th>A_human</th>\n",
       "      <th>G_human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T_orangutan</th>\n",
       "      <td>179</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_orangutan</th>\n",
       "      <td>30</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_orangutan</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>291</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_orangutan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             T_human  C_human  A_human  G_human\n",
       "T_orangutan      179       23        1        0\n",
       "C_orangutan       30      219        2        0\n",
       "A_orangutan        2        1      291       10\n",
       "G_orangutan        0        0       21      169"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length =  948\n",
      "Number of transitionss =  84\n",
      "Number of transversions =  6\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('orangutan_human.csv',index_col = 0)\n",
    "display(data_df)\n",
    "\n",
    "length = np.sum(data_df['A_human']+data_df['C_human']+data_df['G_human']+data_df['T_human'])\n",
    "\n",
    "N_TC = data_df.loc['C_orangutan']['T_human'] + data_df.loc['T_orangutan']['C_human'] # transitions_TC\n",
    "N_AG = data_df.loc['G_orangutan']['A_human'] + data_df.loc['A_orangutan']['G_human'] # transitions_AG\n",
    "\n",
    "N_TA = data_df.loc['T_orangutan']['A_human'] + data_df.loc['A_orangutan']['T_human'] # transversion_TA\n",
    "N_TG = data_df.loc['T_orangutan']['G_human'] + data_df.loc['T_orangutan']['G_human'] # transversion_TG\n",
    "N_CG = data_df.loc['G_orangutan']['C_human'] + data_df.loc['C_orangutan']['G_human'] # transversion_CG\n",
    "N_CA = data_df.loc['C_orangutan']['A_human'] + data_df.loc['A_orangutan']['C_human'] # transversion_CG\n",
    "\n",
    "\n",
    "N_transition = N_TC+N_AG\n",
    "N_transversion = N_TA+N_CG+N_CG+N_CA\n",
    "N_intact = length - N_transition - N_transversion\n",
    "\n",
    "print(\"Sequence length = \", length)\n",
    "print(\"Number of transitionss = \",N_transition)\n",
    "print(\"Number of transversions = \",N_transversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are in total 90 base differences between both mitochondrial 12s RNAs. From this substitutions we have 84 transitions (i.e. ($T\\!\\iff\\!C$) and ($A\\!\\iff\\!G$)), and 6 transversions (rest of substitutions). In Kimuraâ€™s 1980 (K80) nucleotide substitution model that has two parameters:\n",
    "\n",
    "1) The sequence distance $d$ between species. $d=rt$ is the product of the average mutation rate $f$ and the branch length $t$. Since the time difference is usually unknown (unless there are fossil calibrations), one canot differentiate between a fast mutation rate over a long time, agains a slow mutation over a long time. On the contrary the distance $d=rt$ controlling the number of mutations that occured can be inferred when comparing two sequences.\n",
    "\n",
    " 2) The transition/transversion rate ratio ($\\kappa$ = rate_transition/rate_transversion) which accounts for the fact that transitions often occur at higher rates than transversions ($\\kappa\\gg 1$).\n",
    "\n",
    "We need to write a function that returns us the log-likelihood given the distance between two sequences ($d$) and the ratio ($\\kappa$), which can written as $P(data|d,\\kappa)$. The process is a Markovian, and following similar arguments to the ones we saw on the probability theory session we know the probability distribution for each site after a time t is:\n",
    "\n",
    "- Probability of a site staying the same:\n",
    "$P_{intact} = \\frac{1}{4} + \\frac{1}{4}e^{-4kd/(2k+1)} + \\frac{1}{2}e^{-2dk}$\n",
    "- Probability of a site showing a transition:\n",
    "$P_{transition} = \\frac{1}{4} + \\frac{1}{4}e^{-4kd/(2k+1)} - \\frac{1}{2}e^{-2dk}$\n",
    "- Probability of a site showing a transversion:\n",
    "$P_{transversion} = \\frac{1}{2} - \\frac{1}{2}e^{-4kd/(2k+1)}$\n",
    "\n",
    "The resulting likelihood for our observation is the multinomial distribution (similar to the binomial but with more than 2 possible types of results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_intact(k,d):\n",
    "    return 0.25 + 0.25*np.exp(-4*k*d/(2*k+1)) + 0.5*np.exp(-2*d*k)\n",
    "def P_transition(k,d):\n",
    "    return 0.25 + 0.25*np.exp(-4*k*d/(2*k+1)) - 0.5*np.exp(-2*d*k)\n",
    "def P_transversion(k,d):\n",
    "    return 0.5 - 0.5*np.exp(-4*k*d/(2*k+1))\n",
    "\n",
    "def log_likelihood(k,d): # this corresponds to a multinomial, check it!\n",
    "    return N_intact*np.log(P_intact(k,d))+N_transition*np.log(P_transition(k,d))+N_transversion*np.log(P_transversion(k,d)) \n",
    "# usually is easier numerically to work with log_likelihood than likelihoods since they can be really small\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.1** Check that the probabilities of finding a nucleotide intact or mutating make sense by plotting the three probability components $P_j(k)$ for different values of $d$, and exploring the limit cases of $d$, $k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.2 Brute force inference** If we want to obtain the posterior distribution $P(k,d|data)$ we need to evaluate the distributions at *all* possible values of $k$ and $d$. Since this is impossible we could also run MCMC to sample $P(k,d|data)$ in a smart way. A more rudimentary alternative is to divide the parameter space (k,d) into a grid and evaluate the posterior for those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2942970112.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    min_k = #\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First you need to find a limit for your prior that make sense, it should be hard to find them by eye,\n",
    "# but you can evaluate the likelihood at different values of k,d to have an idea of the ranges\n",
    "min_k = #\n",
    "max_k = #\n",
    "min_d = #\n",
    "max_d = #\n",
    "\n",
    "k_range = np.linspace(min_k,max_k,100)\n",
    "d_range = np.linspace(min_d,max_d,100)\n",
    "K,D = np.meshgrid(k_range,d_range)\n",
    "\n",
    "posterior = np.exp(log_likelihood(K,D)) # I could multiply by a prior as well\n",
    "\n",
    "\n",
    "plt.contourf(k_range, d_range, posterior, levels=50, cmap='viridis')  # Contour plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.3 MCMC**. We can also infer the parameters running an implemented MCMC. Implement the MCMC using the loglikelihood defined in the previous plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as Pea_Model:\n",
    "    k_prior = ### Define priors for k and d\n",
    "    d_prior = ###\n",
    "    \n",
    "    # we need to define our custom likelihood\n",
    "    def log_likelihood_name(name,k,d):\n",
    "        return log_likelihood(k,d)\n",
    "    \n",
    "    f_likelihood = ### Check the documentation from pymc on how to introduce a custom likelihood\n",
    "    mcmc_sample = pm.sample(4000, chains = 2, return_inferencedata = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(mcmc_sample) # summary of MCMC statistics\n",
    "posterior = mcmc_sample.to_dataframe()\n",
    "sns.kdeplot(posterior,x=('posterior', 'k'),y=('posterior', 'd'),\n",
    "            cmap=plt.cm.viridis,fill=True,thresh=0,levels = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.4 Just for the braves** Code an MCMC yourself. You can follow the steps of the algorithm we discussed in class. You will have freedom on the choices of the proposal step (take into account the different lengthscales in k and d). Make sure to analyze the trace to evaluate if your results has converged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
