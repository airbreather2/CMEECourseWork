{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical session 2. Penguins!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kristen Gorman visited 3 Antarctic islands of the Palmer Archipelago (Torgersen, Biscoe, and Dream) and collected data about three penguin species (Adelie, Gentoo, and Chinstrap). You can find the full dataset in [their github page](https://allisonhorst.github.io/palmerpenguins/). Today we will use a modified subset of the data (`penguins.csv`) to infer sex and anatomic relationships between the penguins. We will start by loading the required libraries for the notebook and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181</td>\n",
       "      <td>3750</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186</td>\n",
       "      <td>3800</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195</td>\n",
       "      <td>3250</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193</td>\n",
       "      <td>3450</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190</td>\n",
       "      <td>3650</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207</td>\n",
       "      <td>4000</td>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202</td>\n",
       "      <td>3400</td>\n",
       "      <td>female</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193</td>\n",
       "      <td>3775</td>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210</td>\n",
       "      <td>4100</td>\n",
       "      <td>male</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>Dream</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198</td>\n",
       "      <td>3775</td>\n",
       "      <td>female</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0       Adelie  Torgersen            39.1           18.7                181   \n",
       "1       Adelie  Torgersen            39.5           17.4                186   \n",
       "2       Adelie  Torgersen            40.3           18.0                195   \n",
       "3       Adelie  Torgersen            36.7           19.3                193   \n",
       "4       Adelie  Torgersen            39.3           20.6                190   \n",
       "..         ...        ...             ...            ...                ...   \n",
       "337  Chinstrap      Dream            55.8           19.8                207   \n",
       "338  Chinstrap      Dream            43.5           18.1                202   \n",
       "339  Chinstrap      Dream            49.6           18.2                193   \n",
       "340  Chinstrap      Dream            50.8           19.0                210   \n",
       "341  Chinstrap      Dream            50.2           18.7                198   \n",
       "\n",
       "     body_mass_g     sex  year  \n",
       "0           3750    male  2007  \n",
       "1           3800  female  2007  \n",
       "2           3250  female  2007  \n",
       "3           3450  female  2007  \n",
       "4           3650    male  2007  \n",
       "..           ...     ...   ...  \n",
       "337         4000    male  2009  \n",
       "338         3400  female  2009  \n",
       "339         3775    male  2009  \n",
       "340         4100    male  2009  \n",
       "341         3775  female  2009  \n",
       "\n",
       "[342 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # numpy is the standard numeric libray\n",
    "import scipy.stats as ss # scipy is the scientific library, the stats module contains different functions\n",
    "import matplotlib.pyplot as plt # matplotlib is the standard plotting library\n",
    "import seaborn as sns # library for statistical plotting\n",
    "import pymc as pm # library for Bayesian MCMC inference\n",
    "import arviz as az # library to analyze and plot Bayesian results\n",
    "\n",
    "\n",
    "### Loading data\n",
    "import pandas as pd # pandas is a library to manipulate dataframes\n",
    "penguin_df = pd.read_csv('penguins.csv')\n",
    "display(penguin_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Calculating proportions\n",
    "\n",
    "In the 2007, the dataset shows that Kirsten's team observed more female than male Adelie penguinin the island of Togersen.\n",
    "\n",
    "**Question 1.1** We want to evaluate how confident can we be that in that year there were more female than male penguins in the island. To solve this use pyMC to generate a posterior distribution for the ratio $f$ of females in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181</td>\n",
       "      <td>3750</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186</td>\n",
       "      <td>3800</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195</td>\n",
       "      <td>3250</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193</td>\n",
       "      <td>3450</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190</td>\n",
       "      <td>3650</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>38.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>181</td>\n",
       "      <td>3625</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>195</td>\n",
       "      <td>4675</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>34.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>193</td>\n",
       "      <td>3475</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>190</td>\n",
       "      <td>4250</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>37.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>186</td>\n",
       "      <td>3300</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>37.8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>180</td>\n",
       "      <td>3700</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>41.1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>182</td>\n",
       "      <td>3200</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>38.6</td>\n",
       "      <td>21.2</td>\n",
       "      <td>191</td>\n",
       "      <td>3800</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>34.6</td>\n",
       "      <td>21.1</td>\n",
       "      <td>198</td>\n",
       "      <td>4400</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>185</td>\n",
       "      <td>3700</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>38.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>195</td>\n",
       "      <td>3450</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>42.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>197</td>\n",
       "      <td>4500</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>34.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>184</td>\n",
       "      <td>3325</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>46.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>194</td>\n",
       "      <td>4200</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0   Adelie  Torgersen            39.1           18.7                181   \n",
       "1   Adelie  Torgersen            39.5           17.4                186   \n",
       "2   Adelie  Torgersen            40.3           18.0                195   \n",
       "3   Adelie  Torgersen            36.7           19.3                193   \n",
       "4   Adelie  Torgersen            39.3           20.6                190   \n",
       "5   Adelie  Torgersen            38.9           17.8                181   \n",
       "6   Adelie  Torgersen            39.2           19.6                195   \n",
       "7   Adelie  Torgersen            34.1           18.1                193   \n",
       "8   Adelie  Torgersen            42.0           20.2                190   \n",
       "9   Adelie  Torgersen            37.8           17.1                186   \n",
       "10  Adelie  Torgersen            37.8           17.3                180   \n",
       "11  Adelie  Torgersen            41.1           17.6                182   \n",
       "12  Adelie  Torgersen            38.6           21.2                191   \n",
       "13  Adelie  Torgersen            34.6           21.1                198   \n",
       "14  Adelie  Torgersen            36.6           17.8                185   \n",
       "15  Adelie  Torgersen            38.7           19.0                195   \n",
       "16  Adelie  Torgersen            42.5           20.7                197   \n",
       "17  Adelie  Torgersen            34.4           18.4                184   \n",
       "18  Adelie  Torgersen            46.0           21.5                194   \n",
       "\n",
       "    body_mass_g     sex  year  \n",
       "0          3750    male  2007  \n",
       "1          3800  female  2007  \n",
       "2          3250  female  2007  \n",
       "3          3450  female  2007  \n",
       "4          3650    male  2007  \n",
       "5          3625  female  2007  \n",
       "6          4675    male  2007  \n",
       "7          3475  female  2007  \n",
       "8          4250  female  2007  \n",
       "9          3300  female  2007  \n",
       "10         3700  female  2007  \n",
       "11         3200  female  2007  \n",
       "12         3800    male  2007  \n",
       "13         4400    male  2007  \n",
       "14         3700  female  2007  \n",
       "15         3450  female  2007  \n",
       "16         4500    male  2007  \n",
       "17         3325  female  2007  \n",
       "18         4200  female  2007  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2007 19 Adelie penguins where observed in Torgersen, from which 13 were female\n"
     ]
    }
   ],
   "source": [
    "## Loading data\n",
    "\n",
    "f_Adelie = penguin_df['species']=='Adelie' # mask of entries for Adelie penguins\n",
    "f_Torgersen = penguin_df['island']=='Torgersen' # mask of entries for Torgersen island\n",
    "f_2007 = penguin_df['year']==2007 # mask for entries from 2007\n",
    "penguin_subset_df = penguin_df[f_Adelie & f_Torgersen & f_2007] # subset used in the question\n",
    "\n",
    "\n",
    "display(penguin_subset_df)\n",
    "N_penguins = penguin_subset_df.shape[0]\n",
    "N_female = np.sum(penguin_subset_df['sex']=='female')\n",
    "print(\"In 2007 {} Adelie penguins where observed in Torgersen, from which {} were female\".format(N_penguins,N_female))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [p_female]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/sebastian-dohne/anaconda3/envs/pymc_env/lib/python3.12/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/sebastian-dohne/anaconda3/envs/pymc_env/lib/python3.12/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 4_000 draw iterations (2_000 + 8_000 draws total) took 3 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_female</th>\n",
       "      <td>0.495</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3255.0</td>\n",
       "      <td>3459.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "p_female  0.495  0.272    0.03    0.947      0.005    0.003    3255.0   \n",
       "\n",
       "          ess_tail  r_hat  \n",
       "p_female    3459.0    1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To generate the MCMC model you can use the same steps that we used in the previous notebook.\n",
    "# Note that the parameter we are trying to infer is now continuous\n",
    "with pm.Model() as Pea_Model:\n",
    "    f_prior = pm.TruncatedNormal(\"p_female\", mu=0.5, sigma = 0.5 , lower = 0, upper  = 1)\n",
    "    f_likelihood = pm.Binomial(\"observed_females\", n=19, p=0.5, observed=13) \n",
    "    mcmc_sample = pm.sample(4000, chains = 2, return_inferencedata = True)    \n",
    "    \n",
    "az.summary(mcmc_sample) # summary of MCMC statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** Using the posterior distribution you can evaluate different hypothesis regarding $f$: 1) Can we reject the hypothesis that f=1/2? 2) Can we accept the hypothesis that f=1/2? 3) Is the number of females greater than the number of males?. Answer the three questions separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'var names: \"[\\'f\\'] are not present\" in dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.12/site-packages/arviz/utils.py:78\u001b[0m, in \u001b[0;36m_var_names\u001b[0;34m(var_names, data, filter_vars, errors)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     var_names \u001b[38;5;241m=\u001b[39m \u001b[43m_subset_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.12/site-packages/arviz/utils.py:158\u001b[0m, in \u001b[0;36m_subset_list\u001b[0;34m(subset, whole_list, filter_items, warn, errors)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(existing_items) \u001b[38;5;129;01mand\u001b[39;00m (errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39marray(subset)[\u001b[38;5;241m~\u001b[39mexisting_items]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subset\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['f'] are not present\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Remember that you can evalute the hdi using arviz.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m hdi \u001b[38;5;241m=\u001b[39m \u001b[43maz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhdi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmcmc_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvar_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdi_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.94\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 94% credibility interval\u001b[39;00m\n\u001b[1;32m      3\u001b[0m hdi_numpy \u001b[38;5;241m=\u001b[39m hdi[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy() \u001b[38;5;66;03m# you can extract the hdi as numpy arrays as well\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe 94\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m HDI is\u001b[39m\u001b[38;5;124m'\u001b[39m,hdi_numpy)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.12/site-packages/arviz/stats/stats.py:591\u001b[0m, in \u001b[0;36mhdi\u001b[0;34m(ary, hdi_prob, circular, multimodal, skipna, group, var_names, filter_vars, coords, max_modes, dask_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m     ary \u001b[38;5;241m=\u001b[39m get_coords(ary, coords)\n\u001b[0;32m--> 591\u001b[0m var_names \u001b[38;5;241m=\u001b[39m \u001b[43m_var_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m ary \u001b[38;5;241m=\u001b[39m ary[var_names] \u001b[38;5;28;01mif\u001b[39;00m var_names \u001b[38;5;28;01melse\u001b[39;00m ary\n\u001b[1;32m    594\u001b[0m hdi_coord \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigher\u001b[39m\u001b[38;5;124m\"\u001b[39m], dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhdi\u001b[39m\u001b[38;5;124m\"\u001b[39m], attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(hdi_prob\u001b[38;5;241m=\u001b[39mhdi_prob))\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.12/site-packages/arviz/utils.py:83\u001b[0m, in \u001b[0;36m_var_names\u001b[0;34m(var_names, data, filter_vars, errors)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     82\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvar names:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 83\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m var_names\n",
      "\u001b[0;31mKeyError\u001b[0m: 'var names: \"[\\'f\\'] are not present\" in dataset'"
     ]
    }
   ],
   "source": [
    "## Remember that you can evalute the hdi using arviz.\n",
    "hdi = az.hdi(mcmc_sample,var_names=[\"f\"], hdi_prob = 0.94) # 94% credibility interval\n",
    "hdi_numpy = hdi['f'].to_numpy() # you can extract the hdi as numpy arrays as well\n",
    "print('The 94% HDI is',hdi_numpy)\n",
    "\n",
    "## You can access all the values of the trace (posterior) as\n",
    "posteriorf = mcmc_sample.posterior.f # extract the values of N for the posterior distribution\n",
    "posteriorf_all = posteriorf.values.ravel() # flatten the array to gather all the chains in a single array\n",
    "## We can also plot the posterior. In the previous notebook we used a histogram, we can also use a KDE\n",
    "kde = ss.gaussian_kde(posteriorf_all)\n",
    "f_values = np.linspace(0,1,100)\n",
    "plt.plot(f_values,kde(f_values),'-') # plot KDE\n",
    "f_values_hdi = np.linspace(hdi_numpy[0],hdi_numpy[1],100)\n",
    "plt.fill_between(f_values_hdi,kde(f_values_hdi),alpha=0.5) # shade the KDE under the 95% HDR\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('credibility')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical modelling\n",
    "In our analysis of penguin populations, we have focused on individual islands without considering additional data from neighboring islands. Given that the fraction $f$ of females within each island's penguin population is likely to be similar across islands in the same year, we can leverage this information to refine our inference through a hierarchical model. Hierarchical modeling allows us to treat each island's $f$ as originating from a shared distribution, acknowledging that while each island's fraction may vary, these variations are part of a coherent pattern influenced by broader factors.\n",
    "\n",
    "This does not imply a single joint distribution for the number of females in the archipelago rather enables us to infer a specific posterior distribution of $f$ for each island, under the assumption that these distributions are related rather than completely independent. Essentially, hierarchical models connect the prior distributions for $f$ across islands, reflecting our belief in a structured, not random, variation among them.\n",
    "\n",
    "Therefore, the parameters we want to infer are: 1) The credibility distribution of $f$ for each island, and 2) The shared parameters among the islands (hyperprior). In particular, the credibility for the cross-island average $\\mu$, and the cross-island standard deviation $\\sigma$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [mu, sigma, f_Torgersen, f_Biscoe, f_Dream]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/sebastian-dohne/anaconda3/envs/pymc_env/lib/python3.12/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/sebastian-dohne/anaconda3/envs/pymc_env/lib/python3.12/site-packages/rich/live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 40_000 draw iterations (4_000 + 160_000 draws total) took 84 seconds.\n",
      "There were 15319 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mu</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6524.0</td>\n",
       "      <td>9985.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_Torgersen</th>\n",
       "      <td>0.552</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5860.0</td>\n",
       "      <td>9077.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_Biscoe</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7124.0</td>\n",
       "      <td>4057.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_Dream</th>\n",
       "      <td>0.521</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6786.0</td>\n",
       "      <td>8915.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "mu           0.525  0.077   0.378    0.667      0.001    0.001    6524.0   \n",
       "sigma        0.048  0.030   0.006    0.102      0.001    0.000    1073.0   \n",
       "f_Torgersen  0.552  0.080   0.404    0.706      0.001    0.001    5860.0   \n",
       "f_Biscoe     0.502  0.087   0.337    0.665      0.001    0.001    7124.0   \n",
       "f_Dream      0.521  0.077   0.377    0.666      0.001    0.001    6786.0   \n",
       "\n",
       "             ess_tail  r_hat  \n",
       "mu             9985.0   1.00  \n",
       "sigma           340.0   1.01  \n",
       "f_Torgersen    9077.0   1.00  \n",
       "f_Biscoe       4057.0   1.00  \n",
       "f_Dream        8915.0   1.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_Adelie = penguin_df['species']=='Adelie' # mask of entries for Adelie penguins\n",
    "f_2007 = penguin_df['year']==2007 # mask for entries from 2007\n",
    "\n",
    "f_Torgersen = penguin_df['island']=='Torgersen' # mask of entries for Torgersen island\n",
    "f_Biscoe = penguin_df['island']=='Biscoe' # mask of entries for Torgersen island\n",
    "f_Dream = penguin_df['island']=='Dream' # mask of entries for Torgersen island\n",
    "f_female = penguin_df['sex']=='female' # mask of entries for Torgersen island\n",
    "\n",
    "N_Torgersen = np.sum(f_Adelie & f_2007 & f_Torgersen) # Number of Torgersen penguins observed\n",
    "N_Torgersen_female = np.sum(f_Adelie & f_2007 & f_Torgersen & f_female) # Number of female Torgersen penguins observed\n",
    "\n",
    "N_Biscoe = np.sum(f_Adelie & f_2007 & f_Biscoe) # Number of Biscoe penguins observed\n",
    "N_Biscoe_female = np.sum(f_Adelie & f_2007 & f_Biscoe & f_female) # Number of female Biscoe penguins observed\n",
    "\n",
    "N_Dream = np.sum(f_Adelie & f_2007 & f_Dream) # Number of Dream penguins observed\n",
    "N_Dream_female = np.sum(f_Adelie & f_2007 & f_Dream & f_female) # Number of female Dream penguins observed\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # cross-island parameters\n",
    "    mu = pm.Uniform('mu', lower=0, upper =1) #cross-island mean f, the value is between 0,1 using an uninformative prior\n",
    "    sigma = pm.HalfNormal('sigma', sigma = 0.05) #cross-island std f, we don't expect the \"f\" of each island to be very different among each other\n",
    "    \n",
    "    # island-specific parameters\n",
    "    f_Torgersen = pm.TruncatedNormal(\"f_Torgersen\",mu = mu, sigma = sigma, lower = 0, upper = 1) # The prior is taken from the shared prior\n",
    "    f_Biscoe = pm.TruncatedNormal(\"f_Biscoe\",mu = mu, sigma = sigma, lower = 0, upper = 1) # The prior is taken from the shared prior\n",
    "    f_Dream = pm.TruncatedNormal(\"f_Dream\",mu = mu, sigma = sigma, lower = 0, upper = 1) # The prior is taken from the shared prior\n",
    "    \n",
    "    #The likelihood will be the product of all the observations for each island. If you define 3 likelihoods, pymc multiplies them for you!!\n",
    "    lkl_Torgersen = pm.Binomial(\"lkl_Torgersen\", n=N_Torgersen, p = f_Torgersen, observed = N_Torgersen_female)# Write the binomial likelihood \n",
    "    lkl_Biscoe = pm.Binomial(\"lkl_Biscoe\", n=N_Biscoe, p = f_Biscoe, observed = N_Biscoe_female)# Write the binomial likelihood \n",
    "    lkl_Dream = pm.Binomial(\"lkl_Dream\", n=N_Dream, p = f_Dream, observed = N_Dream_female)# Write the binomial likelihood \n",
    "    # \n",
    "    mcmc_sample_hierarchical = pm.sample(40000, chains = 4, return_inferencedata = True)    \n",
    "\n",
    "az.summary(mcmc_sample_hierarchical) # summary of MCMC statistics\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** Compare the hypothesis of the ratio $f$ of female penguins in Torgersen Island with those obtained in Question 1.2. How different are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will use the same Bayesian workflow to study the linear relationship between two variables. This can be done in a straightforward way, since the flexibility of the Bayesian approach enables us to adapt our analysis to various models of likelihood. By incorporating our understanding and beliefs about the possible underlying relationships within the data, we can use the Bayesian approach to constrain our predictions. \n",
    "\n",
    "**Question 2.1** For each penguin, create a scatter plot with bill length on one axis and flipper length on the other. Then, visually inspect the plot to determine if there is a correlation between these two measurements. Hint: since your data is in a Pandas dataframe you can use seaborn's [`scatterplot`](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit a linear regression, we need to write our credibility for the linear relationship in the data. One possible way is to assume that for each species the mean flipper length is a linear function of the bill_length $\\mu_{flipper} = a\\cdot $ bill_length $+ b$. In addition we can assume that the observed flipper_length is normally distributed around the corresponding $\\mu_{flipper}$ with a standard deviation $\\sigma$. And alternative way of writing this relationship that you can find in books is $flipper \\sim \\mathcal{N}(a\\cdot bill+b,\\sigma)$.\n",
    "\n",
    "**Question 2.2** The 3 parameters in our model are $a$, $b$ and $\\sigma$. Before conducting any analysis, What values do you think would fit the data well?\n",
    "\n",
    "**Question 2.3** Fill the gaps in the following code to perform the linear regression using Bayesian inference for the penguins of Torgersen island. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1249894494.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    a = # reasonable prior for a\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "f_Torgersen = penguin_df['island']=='Torgersen' # mask of entries for Torgersen island\n",
    "\n",
    "flipper_length_Torgersen = penguin_df[f_Torgersen]['flipper_length_mm']\n",
    "bill_length_Torgersen = penguin_df[f_Torgersen]['bill_length_mm']\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # you can find a,b,sigma ranges by visual exploration of the data. Some times the analysis is \n",
    "    # easier if the daya is z-score normalized \n",
    "    a = # reasonable prior for a\n",
    "    b = # reasonable prior for b\n",
    "    sigma = # reasonable prior for sigma \n",
    "    \n",
    "    # expected mean as a function of bill_length (it could be any non-linear function as well!)\n",
    "    mu_flipper = a*bill_length_Torgersen + b\n",
    "    \n",
    "    likelihood = pm.Normal(\"lkl\", mu = mu_flipper, sigma = sigma, observed = flipper_length_Torgersen)# Write the binomial likelihood \n",
    "    # \n",
    "    mcmc_sample_hierarchical = pm.sample(10000, chains = 5, return_inferencedata = True)\n",
    "    map = pm.find_MAP() # this tme we will also store the MAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAP: a={},  b={},  sigma={},\".format(map['a'],map['b'],map['sigma']))\n",
    "az.summary(mcmc_sample_hierarchical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** Use the results to infer if there is a linear relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** Posterior predictive checks. The posterior distributions contain values of the parameters with highest credibility but it could be that those \"best\" paramerters, are still not good approximations of the data. For this reason is good to perform posterior predictive checks. In our case we can plot the following on top of the original data:\n",
    "\n",
    "1) The linear fit predicted by the MAP of the posterior distribution. \n",
    "2) We had to assume that the data were normally distributed along our prediction of $\\mu_{flipper}$. In order to check this, we can generate synthetic data given by the posterior and compare if the results qualitative resemble the original data. In some texts this posterior predictive check is denoted as $P(\\,\\widetilde{data}\\,|data)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5)\n",
    "ax = sns.scatterplot(penguin_df,x='bill_length_mm',y='flipper_length_mm',hue='species')\n",
    "ax.scatter(bill_length_Torgersen,\n",
    "            bill_length_Torgersen*map['a']+map['b']+np.random.normal(scale = map['sigma'],size = len(bill_length_Torgersen)),\n",
    "            c = 'red', label = 'posterior predictive')\n",
    "ax.plot(bill_length_Torgersen,\n",
    "            bill_length_Torgersen*map['a']+map['b'],\n",
    "            'r-',label='linear regression')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
