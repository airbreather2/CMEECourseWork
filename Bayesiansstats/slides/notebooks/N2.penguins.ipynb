{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical session 2. Penguins!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kristen Gorman visited 3 Antarctic islands of the Palmer Archipelago (Torgersen, Biscoe, and Dream) and collected data about three penguin species (Adelie, Gentoo, and Chinstrap). You can find the full dataset in [their github page](https://allisonhorst.github.io/palmerpenguins/). Today we will use a modified subset of the data (`penguins.csv`) to infer sex and anatomic relationships between the penguins. We will start by loading the required libraries for the notebook and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'penguins.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m### Loading data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# pandas is a library to manipulate dataframes\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m penguin_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpenguins.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m display(penguin_df)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'penguins.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np # numpy is the standard numeric libray\n",
    "import scipy.stats as ss # scipy is the scientific library, the stats module contains different functions\n",
    "import matplotlib.pyplot as plt # matplotlib is the standard plotting library\n",
    "import seaborn as sns # library for statistical plotting\n",
    "import pymc as pm # library for Bayesian MCMC inference\n",
    "import arviz as az # library to analyze and plot Bayesian results\n",
    "\n",
    "\n",
    "### Loading data\n",
    "import pandas as pd # pandas is a library to manipulate dataframes\n",
    "penguin_df = pd.read_csv('penguins.csv')\n",
    "display(penguin_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Calculating proportions\n",
    "\n",
    "In the 2007, the dataset shows that Kirsten's team observed more female than male Adelie penguinin the island of Togersen.\n",
    "\n",
    "**Question 1.1** We want to evaluate how confident can we be that in that year there were more female than male penguins in the island. To solve this use pyMC to generate a posterior distribution for the ratio $f$ of females in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1004003287.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    f_prior = ### Define the prior disrtibution using a Truncated Normal. the prior could also use a uniform distribution, play with different values to see how it affects the result!\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Loading data\n",
    "\n",
    "f_Adelie = penguin_df['species']=='Adelie' # mask of entries for Adelie penguins\n",
    "f_Torgersen = penguin_df['island']=='Torgersen' # mask of entries for Torgersen island\n",
    "f_2007 = penguin_df['year']==2007 # mask for entries from 2007\n",
    "penguin_subset_df = penguin_df[f_Adelie & f_Torgersen & f_2007] # subset used in the question\n",
    "\n",
    "\n",
    "display(penguin_subset_df)\n",
    "N_penguins = penguin_subset_df.shape[0]\n",
    "N_female = np.sum(penguin_subset_df['sex']=='female')\n",
    "print(\"In 2007 {} Adelie penguins where observed in Torgersen, from which {} were female\".format(N_penguins,N_female))\n",
    "\n",
    "\n",
    "# To generate the MCMC model you can use the same steps that we used in the previous notebook.\n",
    "# Note that the parameter we are trying to infer is now continuous\n",
    "with pm.Model() as Pea_Model:\n",
    "    f_prior = ### Define the prior disrtibution using a Truncated Normal. the prior could also use a uniform distribution, play with different values to see how it affects the result!\n",
    "    f_likelihood = ### Write the corresponding binomial likelihood \n",
    "    mcmc_sample = pm.sample(4000, chains = 2, return_inferencedata = True)    \n",
    "    \n",
    "az.summary(mcmc_sample) # summary of MCMC statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** Using the posterior distribution you can evaluate different hypothesis regarding $f$: 1) Can we reject the hypothesis that f=1/2? 2) Can we accept the hypothesis that f=1/2? 3) Is the number of females greater than the number of males?. Answer the three questions separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remember that you can evalute the hdi using arviz.\n",
    "hdi = az.hdi(mcmc_sample,var_names=[\"f\"], hdi_prob = 0.94) # 94% credibility interval\n",
    "hdi_numpy = hdi['f'].to_numpy() # you can extract the hdi as numpy arrays as well\n",
    "print('The 94% HDI is',hdi_numpy)\n",
    "\n",
    "## You can access all the values of the trace (posterior) as\n",
    "posteriorf = mcmc_sample.posterior.f # extract the values of N for the posterior distribution\n",
    "posteriorf_all = posteriorf.values.ravel() # flatten the array to gather all the chains in a single array\n",
    "## We can also plot the posterior. In the previous notebook we used a histogram, we can also use a KDE\n",
    "kde = ss.gaussian_kde(posteriorf_all)\n",
    "f_values = np.linspace(0,1,100)\n",
    "plt.plot(f_values,kde(f_values),'-') # plot KDE\n",
    "f_values_hdi = np.linspace(hdi_numpy[0],hdi_numpy[1],100)\n",
    "plt.fill_between(f_values_hdi,kde(f_values_hdi),alpha=0.5) # shade the KDE under the 95% HDR\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('credibility')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical modelling\n",
    "In our analysis of penguin populations, we have focused on individual islands without considering additional data from neighboring islands. Given that the fraction $f$ of females within each island's penguin population is likely to be similar across islands in the same year, we can leverage this information to refine our inference through a hierarchical model. Hierarchical modeling allows us to treat each island's $f$ as originating from a shared distribution, acknowledging that while each island's fraction may vary, these variations are part of a coherent pattern influenced by broader factors.\n",
    "\n",
    "This does not imply a single joint distribution for the number of females in the archipelago rather enables us to infer a specific posterior distribution of $f$ for each island, under the assumption that these distributions are related rather than completely independent. Essentially, hierarchical models connect the prior distributions for $f$ across islands, reflecting our belief in a structured, not random, variation among them.\n",
    "\n",
    "Therefore, the parameters we want to infer are: 1) The credibility distribution of $f$ for each island, and 2) The shared parameters among the islands (hyperprior). In particular, the credibility for the cross-island average $\\mu$, and the cross-island standard deviation $\\sigma$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_Adelie = penguin_df['species']=='Adelie' # mask of entries for Adelie penguins\n",
    "f_2007 = penguin_df['year']==2007 # mask for entries from 2007\n",
    "\n",
    "f_Torgersen = penguin_df['island']=='Torgersen' # mask of entries for Torgersen island\n",
    "f_Biscoe = penguin_df['island']=='Biscoe' # mask of entries for Torgersen island\n",
    "f_Dream = penguin_df['island']=='Dream' # mask of entries for Torgersen island\n",
    "f_female = penguin_df['sex']=='female' # mask of entries for Torgersen island\n",
    "\n",
    "N_Torgersen = np.sum(f_Adelie & f_2007 & f_Torgersen) # Number of Torgersen penguins observed\n",
    "N_Torgersen_female = np.sum(f_Adelie & f_2007 & f_Torgersen & f_female) # Number of female Torgersen penguins observed\n",
    "\n",
    "N_Biscoe = np.sum(f_Adelie & f_2007 & f_Biscoe) # Number of Biscoe penguins observed\n",
    "N_Biscoe_female = np.sum(f_Adelie & f_2007 & f_Biscoe & f_female) # Number of female Biscoe penguins observed\n",
    "\n",
    "N_Dream = np.sum(f_Adelie & f_2007 & f_Dream) # Number of Dream penguins observed\n",
    "N_Dream_female = np.sum(f_Adelie & f_2007 & f_Dream & f_female) # Number of female Dream penguins observed\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # cross-island parameters\n",
    "    mu = pm.Uniform('mu', lower=0, upper =1) #cross-island mean f, the value is between 0,1 using an uninformative prior\n",
    "    sigma = pm.HalfNormal('sigma', sigma = 0.05) #cross-island std f, we don't expect the \"f\" of each island to be very different among each other\n",
    "    \n",
    "    # island-specific parameters\n",
    "    f_Torgersen = pm.TruncatedNormal(\"f_Torgersen\",mu = mu, sigma = sigma, lower = 0, upper = 1) # The prior is taken from the shared prior\n",
    "    f_Biscoe = pm.TruncatedNormal(\"f_Biscoe\",mu = mu, sigma = sigma, lower = 0, upper = 1) # The prior is taken from the shared prior\n",
    "    f_Dream = pm.TruncatedNormal(\"f_Dream\",mu = mu, sigma = sigma, lower = 0, upper = 1) # The prior is taken from the shared prior\n",
    "    \n",
    "    #The likelihood will be the product of all the observations for each island. If you define 3 likelihoods, pymc multiplies them for you!!\n",
    "    lkl_Torgersen = pm.Binomial(\"lkl_Torgersen\", n=N_Torgersen, p = f_Torgersen, observed = N_Torgersen_female)# Write the binomial likelihood \n",
    "    lkl_Biscoe = pm.Binomial(\"lkl_Biscoe\", n=N_Biscoe, p = f_Biscoe, observed = N_Biscoe_female)# Write the binomial likelihood \n",
    "    lkl_Dream = pm.Binomial(\"lkl_Dream\", n=N_Dream, p = f_Dream, observed = N_Dream_female)# Write the binomial likelihood \n",
    "    # \n",
    "    mcmc_sample_hierarchical = pm.sample(40000, chains = 4, return_inferencedata = True)    \n",
    "\n",
    "az.summary(mcmc_sample_hierarchical) # summary of MCMC statistics\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** Compare the hypothesis of the ratio $f$ of female penguins in Torgersen Island with those obtained in Question 1.2. How different are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will use the same Bayesian workflow to study the linear relationship between two variables. This can be done in a straightforward way, since the flexibility of the Bayesian approach enables us to adapt our analysis to various models of likelihood. By incorporating our understanding and beliefs about the possible underlying relationships within the data, we can use the Bayesian approach to constrain our predictions. \n",
    "\n",
    "**Question 2.1** For each penguin, create a scatter plot with bill length on one axis and flipper length on the other. Then, visually inspect the plot to determine if there is a correlation between these two measurements. Hint: since your data is in a Pandas dataframe you can use seaborn's [`scatterplot`](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit a linear regression, we need to write our credibility for the linear relationship in the data. One possible way is to assume that for each species the mean flipper length is a linear function of the bill_length $\\mu_{flipper} = a\\cdot $ bill_length $+ b$. In addition we can assume that the observed flipper_length is normally distributed around the corresponding $\\mu_{flipper}$ with a standard deviation $\\sigma$. And alternative way of writing this relationship that you can find in books is $flipper \\sim \\mathcal{N}(a\\cdot bill+b,\\sigma)$.\n",
    "\n",
    "**Question 2.2** The 3 parameters in our model are $a$, $b$ and $\\sigma$. Before conducting any analysis, What values do you think would fit the data well?\n",
    "\n",
    "**Question 2.3** Fill the gaps in the following code to perform the linear regression using Bayesian inference for the penguins of Torgersen island. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_Torgersen = penguin_df['island']=='Torgersen' # mask of entries for Torgersen island\n",
    "\n",
    "flipper_length_Torgersen = penguin_df[f_Torgersen]['flipper_length_mm']\n",
    "bill_length_Torgersen = penguin_df[f_Torgersen]['bill_length_mm']\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # you can find a,b,sigma ranges by visual exploration of the data. Some times the analysis is \n",
    "    # easier if the daya is z-score normalized \n",
    "    a = # reasonable prior for a\n",
    "    b = # reasonable prior for b\n",
    "    sigma = # reasonable prior for sigma \n",
    "    \n",
    "    # expected mean as a function of bill_length (it could be any non-linear function as well!)\n",
    "    mu_flipper = a*bill_length_Torgersen + b\n",
    "    \n",
    "    likelihood = pm.Normal(\"lkl\", mu = mu_flipper, sigma = sigma, observed = flipper_length_Torgersen)# Write the binomial likelihood \n",
    "    # \n",
    "    mcmc_sample_hierarchical = pm.sample(10000, chains = 5, return_inferencedata = True)\n",
    "    map = pm.find_MAP() # this tme we will also store the MAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAP: a={},  b={},  sigma={},\".format(map['a'],map['b'],map['sigma']))\n",
    "az.summary(mcmc_sample_hierarchical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** Use the results to infer if there is a linear relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** Posterior predictive checks. The posterior distributions contain values of the parameters with highest credibility but it could be that those \"best\" paramerters, are still not good approximations of the data. For this reason is good to perform posterior predictive checks. In our case we can plot the following on top of the original data:\n",
    "\n",
    "1) The linear fit predicted by the MAP of the posterior distribution. \n",
    "2) We had to assume that the data were normally distributed along our prediction of $\\mu_{flipper}$. In order to check this, we can generate synthetic data given by the posterior and compare if the results qualitative resemble the original data. In some texts this posterior predictive check is denoted as $P(\\,\\widetilde{data}\\,|data)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5)\n",
    "ax = sns.scatterplot(penguin_df,x='bill_length_mm',y='flipper_length_mm',hue='species')\n",
    "ax.scatter(bill_length_Torgersen,\n",
    "            bill_length_Torgersen*map['a']+map['b']+np.random.normal(scale = map['sigma'],size = len(bill_length_Torgersen)),\n",
    "            c = 'red', label = 'posterior predictive')\n",
    "ax.plot(bill_length_Torgersen,\n",
    "            bill_length_Torgersen*map['a']+map['b'],\n",
    "            'r-',label='linear regression')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
